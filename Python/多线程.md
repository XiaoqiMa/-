## Python Multi-threading
https://www.cnblogs.com/zingp/p/8626834.html

### 多线程

同步的定义是：在发出一个功能调用时，在没有得到结果之前，该调用就不返回，同时其它线程也不能调用这个方法。按照这个定义，其实绝大多数函数都是同步调用。
但是通常说进程、线程同步，往往特指多进程、线程编程时，多个进程、线程之间协同步调，按预定的先后次序进行运行。比如线程A和线程B一起配合，A执行到一定程度依赖B的某个结果，于是停下来示意B运行，B开始执行，执行完将结果返回给A，A接着执行。这里的“同”应该理解为协同、协助、互相配合。
在多线程编程里面，一些敏感数据不允许被多个线程同时访问，此时就使用同步访问技术，保证数据在任何时刻，最多有一个线程访问，以保证数据的完整性。

Thread中，形参target传入函数名，args传入函数对应的参数，参数必须是可迭代对象，如果是元组且只有一个参数必须写成（参数，）的形式，逗号不能省略。

```python
import time
import threading
 
def func(n):
    while n > 0:
        print("name:", threading.current_thread().name, "n:", n)
        n -= 1
        time.sleep(1)
 
t = threading.Thread(target=func, args=(5,))
# t = threading.Thread(target=func, args=(5,), daemon=True) # daemon thread
t.start()
print("main thread：", threading.current_thread().name)
# t.join() # 主线程会在join()处一直等待所有线程都结束之后，再继续运行
if t.is_alive():
	print('alive')
else:
	print('not alive')

print('main thread end')

```

如果要对线程进行高级操作，如发送信号，终止线程，都需要自己实现。下例通过轮询控制线程退出：

```python
import time
from threading import Thread
 
class StopThread:
    def __init__(self):
        self._flag = True
 
    def terminate(self):
        self._flag = False
 
    def run(self, n):
        while self._flag and n > 0:
            print('num>>:', n)
            n -= 1
            time.sleep(1)
 
obj = StopThread()
t = Thread(target=obj.run, args=(11,))
t.start()
 
time.sleep(5)    # 表示do something
 
obj.terminate()  # 终止线程
t.join()
print("主线程结束")

```

Lock有“锁定”或“解锁”两种状态之一。它是在解锁状态下创建的。它有两个基本方法，acquire() 和 release()。
当状态为解锁时，acquire()将状态更改为锁定并立即返回。当状态被锁定时，acquire()块直到对另一个协程中的release()的调用将其改变为解锁，然后acquire()调用将其重置为锁定并返回。
release()方法只应在锁定状态下调用；它将状态更改为已解锁并立即返回。如果尝试释放已解锁的锁，则会引发 RuntimeError。

```python
from threading import Thread
import time
import threading
 
lock = threading.Lock()
 
def add_one(a):
    time.sleep(1)
    lock.acquire()
    a[1] += 1
    lock.release()
    # 上下文管理协议
    # with lock:
    #     a[1] += 1　
 
if __name__ == '__main__':
    array = [0, 1, 4]
    thread_obj_list = []
 
    for i in range(50):
        t = Thread(target=add_one, args=(array,))
        t.start()
        thread_obj_list.append(t)
 
    for j in thread_obj_list:
        j.join()
 
    print("array result::", array)
    # array result:: [0, 51, 4]　　
```

全局解释器锁（英语：Global Interpreter Lock，缩写GIL），是计算机程序设计语言解释器用于同步线程的一种机制，它使得任何时刻仅有一个线程在执行。所以很多人说Python的线程是假线程，并能利用多核，并不能真正并行。之所以感觉到线程并行，是因为线程上下文不断切换的缘故。Python 3.2开始使用新的GIL。新的GIL实现中用一个固定的超时时间来指示当前的线程放弃全局锁。在当前线程保持这个锁，且其他线程请求这个锁时，当前线程就会在5毫秒后被强制释放该锁。关于全局锁，强调三点：

（1）GIL的存在，同一时刻只能有一个线程在运行。

（2）GIL是CPython的特性，Jython，pypy等并无GIL。

（3）Cpython的多线程适用于I/O密集型问题，计算密集型问题可使用多进程编程

在多线程编程中，有时候某个线程依赖另一个线程的状态，需要使用threading库中的Event对象。 Event对象包含一个可由线程设置的信号标志，它允许线程等待某些事件的发生。可将线程设置等待Event对象， 直到有其他线程将Event对象设置为真，这些等待Event对象的线程将开始执行。Event()对象的常用方法：

event对象的一个重要特点是当它被设置为真时会唤醒所有等待它的线程。如果你只想唤醒单个或者一定数目的线程，最好是使用信号量或者 Condition 对象来替代。

```python
event = threading.Event()   # 创建threading.Event()对象
 
event.is_set()   # 获取event的设置值，默认为False
event.set()      # 设置event的值为True
event.clear()    # 设置event的值为False
event.wait()     # 等到event的值被设为True就执行
```

```python
import threading
import time
 
def traffic_light(event):
    count = 0
    event.set()
    while True:
        # 如果计数器[0, 5)之间， 红灯，event=False
        if 0 <= count < 5:
            event.clear()
            print("light is Red")
        # 如果计数器[5, 10)之间， 绿灯，event=True
        elif 5 <= count < 10:
            event.set()
            print("light is Green")
        # 如果计数器大于10，红灯，将event设置为False，计数器置为0
        else:
            event.clear()
            count = 0
        time.sleep(1)
        count += 1
 
def car(name, event):
    while True:
        if not event.is_set():
            # event为False, 表示红灯， 车只能等待
            print("RED, the %s is waiting..." % name)
            # 此处会阻塞住，直到event被设置为True在执行
            event.wait()
            print("Green, The %s going...." % name)
 
e = threading.Event()
light = threading.Thread(target=traffic_light, args=(e,))
light.start()
car1 = threading.Thread(target=car, args=("Tesla", e, ))
car1.start()
```

信号量通常用于防范容量有限的资源，例如数据库服务器。一般而言信号量可以控制释放固定量的线程。比如启动100个线程，信号量的控制值设为5，那么前5个线程拿到信号量之后，其余线程只能阻塞，等到这5个线程释放信号量锁之后才能去拿锁。参见下例：

```python
import threading
import time
 
def func(n):
    # semaphore.acquire()
    with semaphore:
        time.sleep(2)
        print("Thread::", n)
    # semaphore.release()
 
semaphore = threading.BoundedSemaphore(5)   # 信号量, 每次释放5个线程
 
thread_list = []
for i in range(23):
    t = threading.Thread(target=func, args=(i,))
    thread_list.append(t)
    t.start()
 
for j in thread_list:
    j.join()
 
print("all threads done")　

```

两个或多个线程之间相互发送数据最安全的方式可能就是使用 queue 库中的队列了。创建一个线程共享的 Queue 对象，线程通过使用 put()和 get()操作来向队列中添加或者删除元素。Queue对象已经内置了锁机制，编程时不必手动操作锁。下例producer()函数代表包子铺，生产包子放入队列中；consumer()函数代表吃包子的人，不断从队列中取出包子吃掉；以此演示线程间通过队列通信。

```python
from queue import Queue
import threading
import time
 
q = Queue(10)
 
def producer():
    n = 0
    while True:
        q.put("包子%s" % n)
        print("包子铺生产 包子%s" % n)
        n += 1
        time.sleep(2)
 
def consumer():
    while True:
        r = q.get()
        print("bucker 吃掉 %s" % r)
        time.sleep(1)
 
t1 = threading.Thread(target=producer)
t1.start()
t2 = threading.Thread(target=consumer)
t2.start()　　

```

Python3.2开始，增加了标准库concurrent.futures，该库中的ThreadPoolExecutor是自带的线程池
ThreadPoolExecutor还有一个优点就是：任务提交者更方便的从被调用函数中获取返回值。参见下例：

```python
import concurrent.futures
import requests
 
URLS = ['http://www.cnblogs.com/zingp/p/5878330.html',
        'http://www.cnblogs.com/zingp/',
        'https://docs.python.org/']
 
# 爬取网页内容
def load_url(url, timeout):
    with requests.get(url, timeout=timeout) as conn:
        return conn.text
 
with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
    # 创建future对象和对应的url的字典
    future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}
    for future in concurrent.futures.as_completed(future_to_url):
        url = future_to_url[future]
        try:
            data = future.result()
        except Exception as err:
            print('url:%s -- err: %s' % (url, err))
        else:
            print(url, len(data))
```

（1）Python多线程编程常用threading模块。启动一个多线程需要创建一个Thread对象，调用star()方法启动线程。注意is_alive() /join()方法和daemon参数的使用。
（2）python多线程锁有Lock / Rlock， 全局锁GIL。GIL是CPython特性，同一时刻只能运行一个线程，不能利用多核资源。
（3）线程同步原语有Event / Condition / Semaphore / Barrier。Event用于常用语通知全部线程，condition和Semapher常用于通知一定数量的线程， Barrier用于多个线程必须完成某些步骤再一起执行。
（4）Lock / Rlock / Event / Condition / Semaphore 支持上下文管理协议（with语句，好用）。
（5）线程间通信可以用queue模块中的Queue队列，get()和put()已加锁，是线程安全的。qsize()/full()/empty() 等可以获取一个队列的当前大小和状态, 不是线程安全的，尽量别用。
（6）concurrent.futures中的ThreadPoolExecutor是Python3.2之后自带的线程池模块，十分好用，支持with语句，通过future.result()获取线程返回值。
（7）Python多线程适用于I/O密集型问题，CPU密集型问题可以用C代码优化底层算法提升性能，需注意一个写的不好的C语言扩展会导致这个问题更加严重；也可以用pypy或者多进程。



### Python Coroutine (Python 协程)
所以，关于协程可以总结以下两点：

（1）线程的调度是由操作系统负责，协程调度是程序自行负责。

（2）与线程相比，协程减少了无畏的操作系统切换。

实际上当遇到IO操作时做切换才更有意义，（因为IO操作不用占用CPU），如果没遇到IO操作，按照时间片切换，无意义。

多线程相当于，你5分钟在做蒸饭的工作，到了5分钟开始炒菜，又过了5分钟，你又去忙蒸饭。

协程相当于，你淘完米，放在电饭锅，按下煮饭键之后，你开始去炒菜。炒菜的时候油没热，你可以调佐料。这样，你炒两个菜出来，饭蒸好了。整个过程你没闲着，但是节约了不少时间。

如1中所述，代码块A能够中断去执行代码块B，代码块B能够中断，执行代码块A。这不是和yield功能如出一辙吗？我们先回忆一下yield的功能：

(1) 在函数中，语句执行到yield，会返回yield 后面的内容；当再回来执行时，从yield的下一句开始执行；
(2) 使用yield语法的函数是一个生成器；
(3) python3中，通过 `.__next__()` 或者 `next()` 方法获取生成器的下一个值。



```python
from collections import deque
 
def sayHello(n):
    while n > 0:
        print("hello~", n)
        yield n
        n -= 1
    print('say hello')
 
def sayHi(n):
    x = 0
    while x < n:
        print('hi~', x)
        yield
        x += 1
    print("say hi")
 
# 使用yield语句，实现简单任务调度器
class TaskScheduler(object):
    def __init__(self):
        self._task_queue = deque()
 
    def new_task(self, task):
'
        向调度队列添加新的任务
'
        self._task_queue.append(task)
 
    def run(self):
'
        不断运行，直到队列中没有任务
'
        while self._task_queue:
            task = self._task_queue.popleft()
            try:
                next(task)
                self._task_queue.append(task)
            except StopIteration:
                # 生成器结束
                pass
 
sched = TaskScheduler()
sched.new_task(sayHello(10))
sched.new_task(sayHi(15))
sched.run()

#上例执行时，你会看到sayHello()和sayHi() 不断交替执行，当执行sayHello()时，在yield处中断，当执行sayHi()时从yield处中断，切换回sayHello()从yield之后的一句开始执行。。。如此来回交替无缝连接。
```



```python
import asyncio
async def say_hi(n):
    print("start:", n)
    r = await asyncio.sleep(2)
    print("end:", n)
 
loop = asyncio.get_event_loop()
tasks = [say_hi(0), say_hi(1)]
loop.run_until_complete(asyncio.wait(tasks))
loop.close()
 
# start: 1
# start: 0
# 停顿两秒
# end: 1
# end: 0

```



（1）使用协程，只能使用单线程，多线程的便利就一点都用不到。例如，I/O阻塞程序，CPU仍然会将整个任务挂起直到操作完成。
（2） 一旦使用协程，大部分python库并不能很好的兼容，这就会导致要改写大量的标准库函数。
所以，最好别用协程，一旦用不好，协程给程序性能带来的提升，远远弥补不了其带来的灾难。

**不过，遇到实际问题时，多线程和 Asyncio 到底如何选择呢?**

- 如果是 I/O bound，并且 I/O 操作很heavy，需要很多任务 / 线程协同实现，那么使用 Asyncio 更合适。
- 如果是 I/O bound，但是 I/O 操作很快，只需要有限数量的任务 / 线程，那么使用多线程就可以了。
- 如果是 CPU bound，则需要使用多进程来提高程序运行效率。



### Python不是线程安全的

在C语言写的python解释器中存在全局解释器锁，由于全局解释器锁的存在，在同一时间内，python解释器只能运行一个线程的代码，这大大影响了python多线程的性能。而这个解释器锁由于历史原因，现在几乎无法消除。

Python GIL其实是功能和性能之间权衡后的产物，它尤其存在的合理性，也有较难改变的客观因素。从本分的分析中，我们可以做以下一些简单的总结： - 因为GIL的存在，只有IO Bound场景下得多线程会得到较好的性能 - 如果对并行计算性能较高的程序可以考虑把核心部分也成C模块，或者索性用其他语言实现 - GIL在较长一段时间内将会继续存在，但是会不断对其进行改进

python装饰器就是用于拓展原来函数功能的一种函数，这个函数的特殊之处在于它的返回值也是一个函数，使用python装饰器的好处就是在不用更改原函数的代码前提下给函数增加新的功能。

- 不过，遇到实际问题时，多线程和 Asyncio 到底如何选择呢？
如果是 I/O bound，并且 I/O 操作很heavy，需要很多任务 / 线程协同实现，那么使用 Asyncio 更合适。
如果是 I/O bound，但是 I/O 操作很快，只需要有限数量的任务 / 线程，那么使用多线程就可以了。
如果是 CPU bound，则需要使用多进程来提高程序运行效率。



### 参考资料

https://www.cnblogs.com/zingp/p/8626834.html